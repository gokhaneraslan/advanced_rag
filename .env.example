# LLM Provider Configuration
# Choose one: openai, gemini, groq, ollama
LLM_PROVIDER=gemini
LLM_MODEL=gemini-2.5-flash
LLM_TEMPERATURE=0

# API Keys (add your keys here)
GOOGLE_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
GROQ_API_KEY=your_groq_api_key_here

# Memory Configuration
MAX_MEMORY_MESSAGES=10
MEMORY_CLEANUP_DAYS=30

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_RATE_LIMIT=100/minute
ENABLE_CORS=true
CORS_ORIGINS=*

# Logging Configuration
LOG_LEVEL=INFO

# Retrieval Configuration
RETRIEVAL_TOP_K=5
RERANKER_TOP_N=3
SIMILARITY_THRESHOLD=0.95

# Text Splitting Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=100
SPLITTING_METHOD=semantic  # recursive or semantic

# Model Names (usually no need to change)
EMBEDDING_MODEL=BAAI/bge-large-en-v1.5
RERANKER_MODEL=BAAI/bge-reranker-large